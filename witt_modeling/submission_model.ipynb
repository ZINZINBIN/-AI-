{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd0bf5e39365d4d4ec7fe97cfbad94871faa6924a17cde3c0e43b157666c51c6d7d",
   "display_name": "Python 3.8.0 64-bit ('pycaret-env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "source": [
    "## Load and preprocess train data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('../witt_preprocessing/pickles/dangjin_merged.pkl','rb') as f:\n",
    "    dangjin_data = pickle.load(f)\n",
    "with open('../witt_preprocessing/pickles/ulsan_merged.pkl','rb') as f:\n",
    "    ulsan_data = pickle.load(f)\n",
    "\n",
    "\n",
    "# preprocess data for modeling\n",
    "\n",
    "# time as index\n",
    "dangjin_data.set_index('time', inplace=True)\n",
    "ulsan_data.set_index('time', inplace=True)\n",
    "\n",
    "# dangjin - sum target values\n",
    "dangjin_data['dangjin_sum'] = dangjin_data['dangjin'] + dangjin_data['dangjin_floating'] + dangjin_data['dangjin_warehouse']\n",
    "dangjin_data.drop(columns=['dangjin','dangjin_floating','dangjin_warehouse'], inplace=True)\n",
    "\n",
    "# delete rows where target == 0\n",
    "dangjin_data = dangjin_data.loc[dangjin_data['dangjin_sum'] != 0]\n",
    "ulsan_data = ulsan_data.loc[ulsan_data['ulsan'] != 0]"
   ]
  },
  {
   "source": [
    "## Load and preprocess test data (public LB)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    time  dangjin_floating  dangjin_warehouse  dangjin  ulsan\n",
       "0    2021-02-01 01:00:00                 0                  0        0      0\n",
       "1    2021-02-01 02:00:00                 0                  0        0      0\n",
       "2    2021-02-01 03:00:00                 0                  0        0      0\n",
       "3    2021-02-01 04:00:00                 0                  0        0      0\n",
       "4    2021-02-01 05:00:00                 0                  0        0      0\n",
       "..                   ...               ...                ...      ...    ...\n",
       "667  2021-02-28 20:00:00                 0                  0        0      0\n",
       "668  2021-02-28 21:00:00                 0                  0        0      0\n",
       "669  2021-02-28 22:00:00                 0                  0        0      0\n",
       "670  2021-02-28 23:00:00                 0                  0        0      0\n",
       "671  2021-02-28 24:00:00                 0                  0        0      0\n",
       "\n",
       "[672 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>dangjin_floating</th>\n      <th>dangjin_warehouse</th>\n      <th>dangjin</th>\n      <th>ulsan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-02-01 01:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-02-01 02:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-02-01 03:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-02-01 04:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-02-01 05:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>2021-02-28 20:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>668</th>\n      <td>2021-02-28 21:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>669</th>\n      <td>2021-02-28 22:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>670</th>\n      <td>2021-02-28 23:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>671</th>\n      <td>2021-02-28 24:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>672 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('../original_dataset/sample_submission.csv')\n",
    "\n",
    "# 2월 일자만\n",
    "sample_submission_feb = sample_submission.loc[sample_submission['time'].str.contains('2021-02')]\n",
    "sample_submission_feb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(672, 9)\n(672, 9)\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "with open('../witt_preprocessing/pickles/dangjin_fcst.pkl','rb') as f:\n",
    "    dangjin = pickle.load(f)\n",
    "with open('../witt_preprocessing/pickles/ulsan_fcst.pkl','rb') as f:\n",
    "    ulsan = pickle.load(f)\n",
    "\n",
    "# index according to sample submission\n",
    "start, end  = pd.Timestamp('2021-02-01 01:00:00'), pd.Timestamp('2021-03-01-00:00:00') # end == 2021-02-28 24:00:00\n",
    "\n",
    "# slice test data\n",
    "dangjin.set_index('time', inplace=True)\n",
    "dangjin_feb = dangjin.loc[start:end,:]\n",
    "print(dangjin_feb.shape)\n",
    "\n",
    "ulsan.set_index('time', inplace=True)\n",
    "ulsan_feb = ulsan.loc[start:end,:]\n",
    "print(ulsan_feb.shape)"
   ]
  },
  {
   "source": [
    "## Config\n",
    "### X\n",
    "- obs보다 fcst가 좋다\n",
    "- Wind_X와 Wind_Y는 제외하는 것이 좋다\n",
    "- Temperature는 포함하는 것이 좋다\n",
    "- Year_sin은 포함하는 것이 좋다\n",
    "### Hp\n",
    "- min_samples_leaf = 4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols_obs = ['Temperature_obs', 'Humidity_obs','Cloud_obs','Day_cos','Day_sin','Year_cos','Year_sin']\n",
    "x_cols_fcst = ['Temperature_fcst','Humidity_fcst','Cloud_fcst','Day_cos','Day_sin','Year_cos','Year_sin']\n",
    "\n",
    "y_dangjin_cols = ['dangjin_sum']\n",
    "y_ulsan_cols = ['ulsan']\n",
    "\n",
    "RS = 518"
   ]
  },
  {
   "source": [
    "## for public LB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, train_data, x_cols_train, y_cols_train, test_data, x_cols_test):\n",
    "    # print\n",
    "    print('='*50)\n",
    "    print('x_cols_train: ', x_cols_train)\n",
    "    print('y_cols_train: ', y_cols_train)\n",
    "    print('x_cols_test: ', x_cols_test)\n",
    "    print('='*50)\n",
    "\n",
    "    # input-target split\n",
    "    x = train_data.loc[:,x_cols_train]\n",
    "    y = train_data.loc[:,y_cols_train]\n",
    "\n",
    "    # fit\n",
    "    model.fit(x,y)\n",
    "\n",
    "    # predict\n",
    "    test_x = test_data.loc[:,x_cols_test]\n",
    "    predict = model.predict(test_x)\n",
    "\n",
    "    return predict, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['Temperature', 'Humidity', 'Cloud', 'Wind_X', 'Wind_Y', 'Day_cos',\n       'Day_sin', 'Year_cos', 'Year_sin'],\n      dtype='object')\nIndex(['Temperature', 'Humidity', 'Cloud', 'Wind_X', 'Wind_Y', 'Day_cos',\n       'Day_sin', 'Year_cos', 'Year_sin'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dangjin_feb.columns)\n",
    "print(ulsan_feb.columns)\n",
    "\n",
    "x_cols_feb = ['Temperature', 'Humidity', 'Cloud','Day_cos', 'Day_sin', 'Year_cos', 'Year_sin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================================================\n",
      "x_cols_train:  ['Temperature_fcst', 'Humidity_fcst', 'Cloud_fcst', 'Day_cos', 'Day_sin', 'Year_cos', 'Year_sin']\n",
      "y_cols_train:  ['dangjin_sum']\n",
      "x_cols_test:  ['Temperature', 'Humidity', 'Cloud', 'Day_cos', 'Day_sin', 'Year_cos', 'Year_sin']\n",
      "==================================================\n",
      "<ipython-input-10-6262bda0f3d5>:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x,y)\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(criterion='mae', verbose=0, n_jobs=-1, random_state=RS, n_estimators=100, min_samples_leaf=4)\n",
    "\n",
    "dangjin_predict, dangjin_model = predict(model, dangjin_data, x_cols_fcst, y_dangjin_cols, dangjin_feb, x_cols_feb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================================================\n",
      "x_cols_train:  ['Temperature_fcst', 'Humidity_fcst', 'Cloud_fcst', 'Day_cos', 'Day_sin', 'Year_cos', 'Year_sin']\n",
      "y_cols_train:  ['ulsan']\n",
      "x_cols_test:  ['Temperature', 'Humidity', 'Cloud', 'Day_cos', 'Day_sin', 'Year_cos', 'Year_sin']\n",
      "==================================================\n",
      "<ipython-input-10-6262bda0f3d5>:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x,y)\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(criterion='mae', verbose=0, n_jobs=-1, random_state=RS, n_estimators=100, min_samples_leaf=4)\n",
    "\n",
    "ulsan_predict, ulsan_model = predict(model, ulsan_data, x_cols_fcst, y_ulsan_cols, ulsan_feb, x_cols_feb)"
   ]
  },
  {
   "source": [
    "## sample_submission.csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission(dangjin_predict, ulsan_predict):\n",
    "    # sum (doesn't matter)\n",
    "    predict = dangjin_predict + ulsan_predict\n",
    "    # add\n",
    "    sample_submission.iloc[:predict.shape[0],1] = predict\n",
    "\n",
    "    return sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_320(df):\n",
    "    # function to apply\n",
    "    def f(x):\n",
    "        if x<320:\n",
    "            return 320\n",
    "        else:\n",
    "            return x\n",
    "    df['dangjin_floating'] = df['dangjin_floating'].apply(lambda x:f(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     time  dangjin_floating  dangjin_warehouse  dangjin  ulsan\n",
       "0     2021-02-01 01:00:00             320.0                  0        0      0\n",
       "1     2021-02-01 02:00:00             320.0                  0        0      0\n",
       "2     2021-02-01 03:00:00             320.0                  0        0      0\n",
       "3     2021-02-01 04:00:00             320.0                  0        0      0\n",
       "4     2021-02-01 05:00:00             320.0                  0        0      0\n",
       "...                   ...               ...                ...      ...    ...\n",
       "1387  2021-07-08 20:00:00             320.0                  0        0      0\n",
       "1388  2021-07-08 21:00:00             320.0                  0        0      0\n",
       "1389  2021-07-08 22:00:00             320.0                  0        0      0\n",
       "1390  2021-07-08 23:00:00             320.0                  0        0      0\n",
       "1391  2021-07-08 24:00:00             320.0                  0        0      0\n",
       "\n",
       "[1392 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>dangjin_floating</th>\n      <th>dangjin_warehouse</th>\n      <th>dangjin</th>\n      <th>ulsan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-02-01 01:00:00</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-02-01 02:00:00</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-02-01 03:00:00</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-02-01 04:00:00</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-02-01 05:00:00</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1387</th>\n      <td>2021-07-08 20:00:00</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1388</th>\n      <td>2021-07-08 21:00:00</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1389</th>\n      <td>2021-07-08 22:00:00</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1390</th>\n      <td>2021-07-08 23:00:00</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1391</th>\n      <td>2021-07-08 24:00:00</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1392 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "# below_320\n",
    "submission_org = to_submission(dangjin_predict, ulsan_predict)\n",
    "submission_320 = below_320(submission_org)\n",
    "\n",
    "# to csv\n",
    "PATH = 'rf_min-leaf-4_320_ver2.csv'\n",
    "submission_320.to_csv(PATH, index=False)\n",
    "\n",
    "# check\n",
    "pd.read_csv(PATH)"
   ]
  },
  {
   "source": [
    "## Playing with already-submitted data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.read_csv('rf_min-leaf-4_320.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_20(df):\n",
    "    # function to apply\n",
    "    def f(x):\n",
    "        if x>320:\n",
    "            return x+20\n",
    "        else:\n",
    "            return x\n",
    "    df['dangjin_floating'] = df['dangjin_floating'].apply(lambda x:f(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_100(k).to_csv('rf_min-leaf-4_320_add20.csv',index=False)"
   ]
  }
 ]
}